job {
  name: "wikipedia-parser"
  factory_class: "org.apache.samza.job.yarn.YarnJobFactory"

  # YARN config
  yarn {
    package_path: "file://${basedir}/target/${project.artifactId}-${pom.version}-dist.tar.gz"
  }

  # Task config
  task {
    class: "samza.examples.wikipedia.task.WikipediaParserStreamTask"
    input: "kafka.wikipedia-raw"
    checkpoint {
      factory: "org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory"
      system: "kafka"
      # Normally, this would be 3, but we have only one broker.
      replication_factor: 1
    }
  }

  # Metrics
  metrics {
    reporter {
      name: "snapsnot"
      class: "org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory"
      stream: "kafka.metrics"
    }
    reporter {
      name: "jmx"
      class: "org.apache.samza.metrics.reporter.JmxReporterFactory"
    }
  }

  # Serializers
  serializer {
    name: "json"
    class: "org.apache.samza.serializers.JsonSerdeFactory"
  }
  serializer {
    name: "metrics"
    class: "org.apache.samza.serializers.MetricsSnapshotSerdeFactory"
  }

  # Systems
  system {
    name: "kafka"
    samza_factory: "org.apache.samza.system.kafka.KafkaSystemFactory"
    samza_msg_serde: "json"
    stream {
      name: "metrics"
      samza_msg_serde: "metrics"
    }
    options {
      [KafkaSystemConfig] {
        consumer {
          zookeeper_connect: "localhost:2181/"
          auto_offset_reset: "largest"
        }
        producer {
          metadata_broker: "localhost:9092"
          producer_type: "sync"
          # Normally, we'd set this much higher, but we want things to look snappy in the demo.
          batch_num_messages: 1
        }
      }
    }
  }
}
